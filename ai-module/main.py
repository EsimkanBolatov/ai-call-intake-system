from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
import uvicorn
import logging
from pydantic import BaseModel
from typing import Optional, List, Dict, Any
import os
from dotenv import load_dotenv
import base64
import sys
from openai import OpenAI

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—É—Ç–µ–π –∏ —Å–µ—Ä–≤–∏—Å–æ–≤
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
load_dotenv()

from services.speech_to_text import SpeechToTextService
from services.openai_classifier import OpenAIClassifierService
from services.tts_service import TTSService

app = FastAPI(title="AI Call Intake Module")

# CORS –∏ –õ–æ–≥–∏
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è (—Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π)
try:
    speech_service = SpeechToTextService()
    openai_classifier_service = OpenAIClassifierService()
    tts_service = TTSService()
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    logger.info("‚úÖ Services Initialized Successfully")
except Exception as e:
    logger.error(f"‚ùå Error initializing services: {e}")

# --- –ú–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö ---
class ProcessCallRequest(BaseModel):
    sessionId: str
    audioData: str 
    history: List[Dict[str, str]] = [] 

class ProcessCallResponse(BaseModel):
    userText: str
    responseText: str
    audioBase64: Optional[str] = None
    incident: Dict[str, Any] = {}

# --- –ü—Ä–æ–º–ø—Ç –î–∏—Å–ø–µ—Ç—á–µ—Ä–∞ ---
SYSTEM_PROMPT = """–¢—ã ‚Äî –æ–ø—ã—Ç–Ω—ã–π –æ–ø–µ—Ä–∞—Ç–æ—Ä —Å–ª—É–∂–±—ã 112 (–ö–∞–∑–∞—Ö—Å—Ç–∞–Ω). 
–¢–≤–æ—è —Ü–µ–ª—å: —É—Å–ø–æ–∫–æ–∏—Ç—å, —É–∑–Ω–∞—Ç—å –°–£–¢–¨ –ø—Ä–æ–∏—Å—à–µ—Å—Ç–≤–∏—è –∏ –ê–î–†–ï–°.
–û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è). –ù–µ —Ç—Ä–∞—Ç—å –≤—Ä–µ–º—è –Ω–∞ –≤–µ–∂–ª–∏–≤–æ—Å—Ç—å, –µ—Å–ª–∏ —Å–∏—Ç—É–∞—Ü–∏—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è.
–ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –º–æ–ª—á–∏—Ç –∏–ª–∏ –≥–æ–≤–æ—Ä–∏—Ç –Ω–µ–≤–Ω—è—Ç–Ω–æ, –ø–µ—Ä–µ—Å–ø—Ä–æ—Å–∏.
"""

# --- –≠–Ω–¥–ø–æ–∏–Ω—Ç—ã ---

@app.get("/health")
def health():
    return {"status": "ok", "version": "updated_v2"}

@app.post("/process-call", response_model=ProcessCallResponse)
async def process_call(request: ProcessCallRequest):
    try:
        session_id = request.sessionId
        logger.info(f"[{session_id}] üì® Processing audio chunk...")

        # 1. Audio -> Text
        try:
            audio_bytes = base64.b64decode(request.audioData)
            user_text = speech_service.transcribe(audio_bytes, "ru")
        except Exception as e:
            logger.warning(f"Decoding failed: {e}")
            return ProcessCallResponse(userText="", responseText="")

        # –§–∏–ª—å—Ç—Ä —Ç–∏—à–∏–Ω—ã
        if not user_text or len(user_text.strip()) < 2:
            return ProcessCallResponse(userText="", responseText="")

        logger.info(f"[{session_id}] üó£Ô∏è User: {user_text}")

        # 2. Text -> AI Response
        messages = [{"role": "system", "content": SYSTEM_PROMPT}]
        # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 4 —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)
        messages.extend(request.history[-4:]) 
        messages.append({"role": "user", "content": user_text})

        completion = client.chat.completions.create(
            model="gpt-4o-mini", messages=messages, max_tokens=100
        )
        ai_text = completion.choices[0].message.content
        logger.info(f"[{session_id}] ü§ñ AI: {ai_text}")

        # 3. AI -> Incident Data (–¥–ª—è –ï–†–î–†)
        # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π –æ—Ç–≤–µ—Ç, —á—Ç–æ–±—ã –æ–±–Ω–æ–≤–ª—è—Ç—å –∫–∞—Ä—Ç–æ—á–∫—É –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
        classification = openai_classifier_service.classify(user_text)
        incident_data = {
            "type": classification.categories[0] if classification.categories else "Unknown",
            "address": classification.extracted_info.get("address", ""),
            "priority": classification.priority,
            "description": user_text
        }

        # 4. Text -> Audio
        audio_response = tts_service.generate_speech(ai_text, "ru")
        audio_b64 = base64.b64encode(audio_response).decode('utf-8') if audio_response else None

        return ProcessCallResponse(
            userText=user_text,
            responseText=ai_text,
            audioBase64=audio_b64,
            incident=incident_data
        )

    except Exception as e:
        logger.error(f"‚ùå Error in process-call: {e}")
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    # –í–ê–ñ–ù–û: reload=True
    uvicorn.run("main:app", host="0.0.0.0", port=8001, reload=True)